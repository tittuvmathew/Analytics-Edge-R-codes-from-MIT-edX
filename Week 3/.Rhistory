exp(2)
exp(1)
exp(1)/(exp(1)+exp(-2)+exp(0.5))
setwd("E:/MOOC/edX/Analytics Edge/Week 3")
# Creating our Prediction Model
nonvars = c("year", "songtitle", "artistname", "songID", "artistID")
SongsTrain = SongsTrain[ , !(names(SongsTrain) %in% nonvars) ]
songs = read.csv("songs.csv" )
str(songs)
songs_2010 = subset(songs, year == 2010)
nrow(songs_2010)
songs_MJ = subset(songs,artistname == "Michael Jackson")
# How many songs does the dataset include for which the artist name is "Michael Jackson"?
nrow(songs_MJ)
summary(songs_MJ)
str(songs_MJ)
# Which of these songs by Michael Jackson made it to the Top 10? Select all that apply.
songs_MJ_top10 = subset(songs_MJ,Top10 == 1)
unique(songs_MJ_top10$songtitle)
# The variable corresponding to the estimated time signature (timesignature) is discrete,
# meaning that it only takes integer values (0, 1, 2, 3, . . . ).
# What are the values of this variable that occur in our dataset? Select all that apply.
unique(songs$timesignature)
# Which timesignature value is the most frequent among songs in our dataset?
table(songs$timesignature)
# Out of all of the songs in our dataset, the song with the highest tempo is one of the following songs. Which one is it?
pos1 = which.max(songs$tempo)
songs$songtitle[pos1]
# Creating prediction model
songs = read.csv("songs.csv" )
SongsTest = subset(songs,year==2010)
SongsTrain = subset(songs,year<=2009)
# Creating our Prediction Model
nonvars = c("year", "songtitle", "artistname", "songID", "artistID")
# Creating our Prediction Model
nonvars = c("year", "songtitle", "artistname", "songID", "artistID")
SongsTrain = SongsTrain[ , !(names(SongsTrain) %in% nonvars) ]
SongsTest = SongsTest[ , !(names(SongsTest) %in% nonvars) ]
SongsLog1 = glm(Top10 ~ ., data=SongsTrain, family=binomial)
summary(SongsLog1)
# Beware of Multicollinearity Issues!
cor(SongsTrain[c("loudness","energy")])
# Model 2
SongsLog2 = glm(Top10 ~ . - loudness, data=SongsTrain, family=binomial)
summary(SongsLog2)
# Model 3
SongsLog2 = glm(Top10 ~ . - energy, data=SongsTrain, family=binomial)
# Model 3
SongsLog3 = glm(Top10 ~ . - energy, data=SongsTrain, family=binomial)
# Model 2
SongsLog2 = glm(Top10 ~ . - loudness, data=SongsTrain, family=binomial)
# Model 3
SongsLog3 = glm(Top10 ~ . - energy, data=SongsTrain, family=binomial)
summary(SongsLog3)
# Validating Our Model
pred3 = predict(SongsLog3, type = "response", newdata = SongsTest)
table(SongsTest$Top10, pred3 > 0.45)
(309+19)/(309+5+40+19)
# Baseline Model
table(SongsTest$Top10)
59/sum(1+314+59)
59/(1+314+59)
# Problem 4.3
pred3 = predict(SongsLog3, type = "response", newdata = SongsTest)
table(SongsTest$Top10, pred3 >= 0.45)
19/(19+40)
309/(309+5)
setwd("E:/MOOC/edX/Analytics Edge/Week 3")
parole = read.csv("parole.csv")
nrow(parole)
summary(parole)
str(parole)
nrow(subset(parole,violator==1))
unique(parole$state)
unique(parole$race)
unique(parole$state)
unique(parole$crime)
# as.factor()
parole$state = as.factor(parole$state)
parole$crime = as.factor(parole$crime)
summary(parole)
parole = read.csv("parole.csv")
summary(parole)
# Splitting into a Training and Testing Set
set.seed(144)
library(caTools)
split = sample.split(parole$violator, SplitRatio = 0.7)
train = subset(parole, split == TRUE)
test = subset(parole, split == FALSE)
#  Building a Logistic Regression Model
Model1 = glm(violator ~ ., data=train, family=binomial)
summary(Model1)
parole = read.csv("parole.csv")
nrow(parole)
str(parole)
nrow(subset(parole,violator==1))
# as.factor()
parole$state = as.factor(parole$state)
parole$crime = as.factor(parole$crime)
summary(parole)
# Splitting into a Training and Testing Set
set.seed(144)
library(caTools)
split = sample.split(parole$violator, SplitRatio = 0.7)
train = subset(parole, split == TRUE)
test = subset(parole, split == FALSE)
#  Building a Logistic Regression Model
Model1 = glm(violator ~ ., data=train, family=binomial)
summary(Model1)
exp(1.6119919)
# Building a Logistic Regression Model
male=1
race=1
age=50
state2=0
state3=0
state4=0
time.served=3
max.sentence=12
multiple.offenses=0
crime2=1
crime3=0
crime4=0
logodds =-4.2411574 + 0.3869904*male + 0.8867192*race - 0.0001756*age + 0.4433007*state2 + 0.8349797*state3 - 3.3967878*state4 - 0.1238867*time.served + 0.0802954*max.sentence + 1.6119919*multiple.offenses + 0.6837143*crime2 - 0.2781054*crime3 - 0.0117627*crime4
logodds
exp(logodds)
1/(1+exp(-logodds))
# Prediction
pred1 = predict(Model1, type = "response", newdata = test)
summary(pred1)
# Evaluating the Model on the Testing Set
table(Test$violator, pred1 >= 0.5)
# Evaluating the Model on the Testing Set
table(test$violator, pred1 >= 0.5)
12/(12+11)
167/(167+12)
(167+12)/(167+24+11)
# What is the accuracy of a simple model that predicts that every parolee is a non-violator?
table(test$violator)
179/(179+23)
# AUC
library(ROCR)
# AUC
library("ROCR")
as.numeric(performance(pred1,"auc")@y.values)
# AUC
library("ROCR")
violator_pred = prediction(pred1, test$violator)
as.numeric(performance(violator_pred,"auc")@y.values)
loan = read.csv("loans.csv")
str(loan)
# What proportion of the loans in the dataset were not paid in full?
table(loan$not.fully.paid)
1533/(1533+8045)
# Which of the following variables has at least one missing observation? Select all that apply.
summary(loan)
# Preparing the Dataset
loans_imputed = read.csv("loans_imputed.csv")
# Prediction models
set.seed(144)
library(caTools)
split = sample.split(loans_imputed$not.fully.paid, SplitRatio = 0.7)
train = subset(parole, split == TRUE)
test = subset(parole, split == FALSE)
Model1 = glm(not.fully.paid ~ ., data=train, family=binomial)
# Prediction models
set.seed(144)
library(caTools)
split = sample.split(loans_imputed$not.fully.paid, SplitRatio = 0.7)
train = subset(parole, split == TRUE)
test = subset(parole, split == FALSE)
Model1 = glm(not.fully.paid ~ ., data=train, family=binomial)
Model1 = glm(not.fully.paid~., data=train, family="binomial")
# Preparing the Dataset
loans_imputed = read.csv("loans_imputed.csv")
# Prediction models
set.seed(144)
library(caTools)
split = sample.split(loans_imputed$not.fully.paid, SplitRatio = 0.7)
train = subset(parole, split == TRUE)
test = subset(parole, split == FALSE)
Model1 = glm(not.fully.paid~., data=train, family="binomial")
mod = glm(not.fully.paid~., data=train, family="binomial")
# Prediction models
set.seed(144)
library(caTools)
split = sample.split(loans_imputed$not.fully.paid, SplitRatio = 0.7)
train = subset(loans_imputed, split == TRUE)
test = subset(loans_imputed, split == FALSE)
Model1 = glm(not.fully.paid~., data=train, family="binomial")
summary(Model1)
-9.317e-03 * (10)
exp(0.09317)
# Prediction Models
predicted.risk = predict(Model1, type = "response", newdata = test)
# Prediction Models
test$predicted.risk = predict(Model1, type = "response", newdata = test)
table(test$not.fully.paid, test$predicted.risk <=0.5 )
(13+457)/(13+457+3+2400)
table(test$not.fully.paid, test$predicted.risk >=0.5 )
(2400+3)/(2400+13+3+457)
table(test$)
table(test$not.fully.paid)
460/(2413+460)
2413/(2413+460)
# Use the ROCR package to compute the test set AUC
loan_pred = prediction(test$predicted.risk, test$not.fully.paid)
as.numeric(performance(loan_pred,"auc")@y.values)
# bivariate
bivariate = glm(not.fully.paid~int.rate, data=train, family="binomial")
summary(bivariate)
# Predict bivariate
pred.bivariate = predict(bivariate, newdata=test, type="response")
summary(pred.bivariate)
# Computing the Profitability of an Investment
test$profit = exp(test$int.rate*3) - 1
test$profit[test$not.fully.paid == 1] = -1  # lender looses all the money
summary(test$profit)
# An Investment Strategy Based on Risk
highInterest = subset(test, int.rate >= 0.15)
mean(highInterest$profit)
table(highInterest)
table(highInterest$not.fully.paid)
327/(327+110)
1 - 327/(327+110)
cutoff = sort(highInterest$predicted.risk, decreasing=FALSE)[100]
selectedLoans = subset(highInterest, predicted.risk <= cutoff)
sum(selectedLoans$profit)
summary(test$profit)
# Computing the Profitability of an Investment
test$profit = 10 * exp(test$int.rate*3) - 10
test$profit[test$not.fully.paid == 1] = -10  # lender looses all the money
summary(test$profit)
# Computing the Profitability of an Investment
test$profit = 100 * exp(test$int.rate*3) - 100
test$profit[test$not.fully.paid == 1] = -100  # lender looses all the money
summary(test$profit)
# Computing the Profitability of an Investment
test$profit = 1 * exp(test$int.rate*3) - 1
test$profit[test$not.fully.paid == 1] = -1  # lender looses all the money
summary(test$profit)
# An Investment Strategy Based on Risk
# Choose those test  data having high interest rate greater than or equal to 1
highInterest = subset(test, int.rate >= 0.15)
cutoff = sort(highInterest$predicted.risk, decreasing=FALSE)[100]
cutoff
summary(highInterest)
str(highInterest)
cutoff = sort(highInterest$predicted.risk, decreasing=FALSE)#[100]
cutoff
# Choose the 100'th cutoff predicted risk from the smallest limit
cutoff = sort(highInterest$predicted.risk, decreasing=FALSE)[100]
selectedLoans = subset(highInterest, predicted.risk <= cutoff)
sum(selectedLoans$profit)
# How many of 100 selected loans were not paid back in full?
table(selectedLoans$not.fully.paid)
baseball = read.csv("baseball.csv")
str(baseball)
unique(baseball$Team)
length(unique(baseball$Team))
length(unique(baseball$Year))
table(baseball$Team,baseball$Year)
nrow(baseball)
# How many team/year pairs are there in the whole dataset?
nrow(baseball)
# Limiting to Teams Making the Playoffs
table(baseball$Year)
# Limiting to Teams Making the Playoffs
len(table(baseball$Year))
# Limiting to Teams Making the Playoffs
length(table(baseball$Year))
baseball = subset(baseball,baseball$Playoffs == 1)
nrow(baseball)
# Limiting to Teams Making the Playoffs
table(baseball$Year)
# Limiting to Teams Making the Playoffs
unique(table(baseball$Year))
# Adding an Important Predictor
PlayoffTable = table(baseball$Year)
names(PlayoffTable)
PlayoffTable[c("1990","2001")]
baseball$NumCompetitors = PlayoffTable[baseball$Year]
PlayoffTable[baseball$Year]
PlayoffTable(baseball$Year)
PlayoffTable[as.character(baseball$Year)]
PlayoffTable(as.character(baseball$Year))
# Adding an Important Predictor
PlayoffTable[c("1990","2001")]
baseball$NumCompetitors = PlayoffTable[as.character(baseball$Year)]
Eight_team_playoff = subset(baseball,baseball$NumCompetitors == 8)
nrow(Eight_team_playoff)
baseball$RankPlayoffs
as.numeric(baseball$RankPlayoffs==1)
# Bivariate Models for Predicting World Series Winner
baseball$WorldSeries = as.numeric(baseball$RankPlayoffs == 1)
nrow(subset(baseball,baseball$WorldSeries == 0))
# Bivariate Models for Predicting World Series Winner
Model_year = glm(WorldSeries ~ Year,data=baseball, family = binomial)
summary(Model_year)
Model_RS = glm(WorldSeries ~ RS,data=baseball, family = binomial)
summary(Model_RS)
Model_RA = glm(WorldSeries ~ RA,data=baseball, family = binomial)
summary(Model_RA)
Model_W = glm(WorldSeries ~ W,data=baseball, family = binomial)
summary(MModel_W)
summary(Model_W)
Model_OBP = glm(WorldSeries ~ OBP,data=baseball, family = binomial)
summary(Model_OBP)
Model_SLG = glm(WorldSeries ~ SLG,data=baseball, family = binomial)
summary(Model_SLG)
Model_BA = glm(WorldSeries ~ BA,data=baseball, family = binomial)
summary(Model_BA)
Model_RankSeason = glm(WorldSeries ~ RankSeason,data=baseball, family = binomial)
summary(Model_RankSeason)
Model_OOBP = glm(WorldSeries ~ OOBP,data=baseball, family = binomial)
summary(Model_OOBP)
Model_OSLG = glm(WorldSeries ~ OSLG,data=baseball, family = binomial)
summary(Model_OSLG)
Model_NumCompetitors = glm(WorldSeries ~ NumCompetitors,data=baseball, family = binomial)
summary(Model_NumCompetitors)
Model_League = glm(WorldSeries ~ League,data=baseball, family = binomial)
summary(Model_League)
# Multivariate Models for Predicting World Series Winner
multimodal = glm(WorldSeries ~ Year+RA+RankSeason + NumCompetitors,data=baseball,family = binomial)
summary(multimodal)
# Correlation
cor(baseball[c("Year","RA","RankSeason","NumCompetitors")])
